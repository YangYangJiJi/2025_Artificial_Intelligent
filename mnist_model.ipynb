{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangYangJiJi/2025_Artificial_Intelligent/blob/main/mnist_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Mydrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_fURG1PST29",
        "outputId": "5b6f2863-bfa1-45f9-9634-da836fa3175a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Mydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99Ktn6LLQP7W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f74ad7ee-c75a-4f88-ffdb-25e7482255ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m335,114\u001b[0m (1.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">335,114</span> (1.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m335,114\u001b[0m (1.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">335,114</span> (1.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4642 - loss: 1.9100 - val_accuracy: 0.8514 - val_loss: 0.6390\n",
            "Epoch 2/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8561 - loss: 0.5717 - val_accuracy: 0.8926 - val_loss: 0.3947\n",
            "Epoch 3/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.4008 - val_accuracy: 0.9057 - val_loss: 0.3297\n",
            "Epoch 4/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.3453 - val_accuracy: 0.9147 - val_loss: 0.2964\n",
            "Epoch 5/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.3111 - val_accuracy: 0.9203 - val_loss: 0.2737\n",
            "Epoch 6/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.2904 - val_accuracy: 0.9257 - val_loss: 0.2572\n",
            "Epoch 7/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2711 - val_accuracy: 0.9293 - val_loss: 0.2425\n",
            "Epoch 8/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.2469 - val_accuracy: 0.9328 - val_loss: 0.2291\n",
            "Epoch 9/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2373 - val_accuracy: 0.9362 - val_loss: 0.2178\n",
            "Epoch 10/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.2197 - val_accuracy: 0.9413 - val_loss: 0.2087\n",
            "Epoch 11/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.2115 - val_accuracy: 0.9427 - val_loss: 0.2029\n",
            "Epoch 12/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.2069 - val_accuracy: 0.9456 - val_loss: 0.1942\n",
            "Epoch 13/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9440 - loss: 0.1975 - val_accuracy: 0.9477 - val_loss: 0.1845\n",
            "Epoch 14/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.1786 - val_accuracy: 0.9498 - val_loss: 0.1778\n",
            "Epoch 15/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.1722 - val_accuracy: 0.9509 - val_loss: 0.1722\n",
            "Epoch 16/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9516 - loss: 0.1680 - val_accuracy: 0.9503 - val_loss: 0.1704\n",
            "Epoch 17/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1624 - val_accuracy: 0.9537 - val_loss: 0.1625\n",
            "Epoch 18/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1574 - val_accuracy: 0.9544 - val_loss: 0.1574\n",
            "Epoch 19/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1510 - val_accuracy: 0.9571 - val_loss: 0.1537\n",
            "Epoch 20/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1412 - val_accuracy: 0.9572 - val_loss: 0.1494\n",
            "Epoch 21/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1388 - val_accuracy: 0.9584 - val_loss: 0.1461\n",
            "Epoch 22/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1336 - val_accuracy: 0.9601 - val_loss: 0.1420\n",
            "Epoch 23/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1260 - val_accuracy: 0.9592 - val_loss: 0.1402\n",
            "Epoch 24/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.1237 - val_accuracy: 0.9624 - val_loss: 0.1360\n",
            "Epoch 25/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.1225 - val_accuracy: 0.9624 - val_loss: 0.1342\n",
            "Epoch 26/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1113 - val_accuracy: 0.9634 - val_loss: 0.1322\n",
            "Epoch 27/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.1145 - val_accuracy: 0.9610 - val_loss: 0.1326\n",
            "Epoch 28/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1117 - val_accuracy: 0.9645 - val_loss: 0.1275\n",
            "Epoch 29/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1078 - val_accuracy: 0.9657 - val_loss: 0.1250\n",
            "Epoch 30/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.1040 - val_accuracy: 0.9657 - val_loss: 0.1221\n",
            "Epoch 31/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0982 - val_accuracy: 0.9663 - val_loss: 0.1211\n",
            "Epoch 32/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.0959 - val_accuracy: 0.9663 - val_loss: 0.1188\n",
            "Epoch 33/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0960 - val_accuracy: 0.9674 - val_loss: 0.1162\n",
            "Epoch 34/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0877 - val_accuracy: 0.9678 - val_loss: 0.1160\n",
            "Epoch 35/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9763 - loss: 0.0875 - val_accuracy: 0.9681 - val_loss: 0.1149\n",
            "Epoch 36/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0838 - val_accuracy: 0.9689 - val_loss: 0.1126\n",
            "Epoch 37/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0847 - val_accuracy: 0.9674 - val_loss: 0.1135\n",
            "Epoch 38/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0779 - val_accuracy: 0.9690 - val_loss: 0.1096\n",
            "Epoch 39/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0761 - val_accuracy: 0.9695 - val_loss: 0.1083\n",
            "Epoch 40/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0741 - val_accuracy: 0.9683 - val_loss: 0.1091\n",
            "Epoch 41/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0708 - val_accuracy: 0.9697 - val_loss: 0.1069\n",
            "Epoch 42/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0733 - val_accuracy: 0.9690 - val_loss: 0.1060\n",
            "Epoch 43/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0666 - val_accuracy: 0.9707 - val_loss: 0.1047\n",
            "Epoch 44/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0687 - val_accuracy: 0.9693 - val_loss: 0.1047\n",
            "Epoch 45/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0676 - val_accuracy: 0.9703 - val_loss: 0.1033\n",
            "Epoch 46/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0648 - val_accuracy: 0.9702 - val_loss: 0.1034\n",
            "Epoch 47/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0605 - val_accuracy: 0.9703 - val_loss: 0.1007\n",
            "Epoch 48/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0599 - val_accuracy: 0.9707 - val_loss: 0.1013\n",
            "Epoch 49/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0586 - val_accuracy: 0.9718 - val_loss: 0.0988\n",
            "Epoch 50/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0569 - val_accuracy: 0.9711 - val_loss: 0.0993\n",
            "Epoch 51/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0537 - val_accuracy: 0.9717 - val_loss: 0.0987\n",
            "Epoch 52/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0549 - val_accuracy: 0.9720 - val_loss: 0.0968\n",
            "Epoch 53/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0539 - val_accuracy: 0.9714 - val_loss: 0.0977\n",
            "Epoch 54/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0548 - val_accuracy: 0.9716 - val_loss: 0.0976\n",
            "Epoch 55/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0481 - val_accuracy: 0.9718 - val_loss: 0.0963\n",
            "Epoch 56/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0452 - val_accuracy: 0.9722 - val_loss: 0.0949\n",
            "Epoch 57/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0452 - val_accuracy: 0.9726 - val_loss: 0.0942\n",
            "Epoch 58/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0495 - val_accuracy: 0.9732 - val_loss: 0.0935\n",
            "Epoch 59/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0445 - val_accuracy: 0.9722 - val_loss: 0.0932\n",
            "Epoch 60/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0437 - val_accuracy: 0.9728 - val_loss: 0.0933\n",
            "Epoch 61/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0419 - val_accuracy: 0.9722 - val_loss: 0.0951\n",
            "Epoch 62/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0420 - val_accuracy: 0.9725 - val_loss: 0.0936\n",
            "Epoch 63/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0418 - val_accuracy: 0.9725 - val_loss: 0.0917\n",
            "Epoch 64/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0390 - val_accuracy: 0.9734 - val_loss: 0.0919\n",
            "Epoch 65/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0380 - val_accuracy: 0.9741 - val_loss: 0.0912\n",
            "Epoch 66/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0375 - val_accuracy: 0.9737 - val_loss: 0.0931\n",
            "Epoch 67/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0371 - val_accuracy: 0.9724 - val_loss: 0.0916\n",
            "Epoch 68/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0347 - val_accuracy: 0.9745 - val_loss: 0.0903\n",
            "Epoch 69/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0347 - val_accuracy: 0.9753 - val_loss: 0.0910\n",
            "Epoch 70/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0323 - val_accuracy: 0.9737 - val_loss: 0.0898\n",
            "Epoch 71/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0314 - val_accuracy: 0.9731 - val_loss: 0.0930\n",
            "Epoch 72/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0319 - val_accuracy: 0.9739 - val_loss: 0.0938\n",
            "Epoch 73/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0303 - val_accuracy: 0.9751 - val_loss: 0.0898\n",
            "Epoch 74/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0302 - val_accuracy: 0.9739 - val_loss: 0.0901\n",
            "Epoch 75/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0301 - val_accuracy: 0.9737 - val_loss: 0.0901\n",
            "Epoch 76/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0293 - val_accuracy: 0.9750 - val_loss: 0.0895\n",
            "Epoch 77/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0288 - val_accuracy: 0.9746 - val_loss: 0.0896\n",
            "Epoch 78/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0274 - val_accuracy: 0.9741 - val_loss: 0.0888\n",
            "Epoch 79/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0259 - val_accuracy: 0.9746 - val_loss: 0.0899\n",
            "Epoch 80/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0256 - val_accuracy: 0.9734 - val_loss: 0.0902\n",
            "Epoch 81/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0239 - val_accuracy: 0.9739 - val_loss: 0.0901\n",
            "Epoch 82/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0245 - val_accuracy: 0.9747 - val_loss: 0.0892\n",
            "Epoch 83/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0237 - val_accuracy: 0.9746 - val_loss: 0.0895\n",
            "Epoch 84/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0240 - val_accuracy: 0.9747 - val_loss: 0.0891\n",
            "Epoch 85/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0227 - val_accuracy: 0.9747 - val_loss: 0.0891\n",
            "Epoch 86/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0225 - val_accuracy: 0.9744 - val_loss: 0.0895\n",
            "Epoch 87/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0225 - val_accuracy: 0.9758 - val_loss: 0.0888\n",
            "Epoch 88/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0204 - val_accuracy: 0.9755 - val_loss: 0.0890\n",
            "Epoch 89/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0203 - val_accuracy: 0.9744 - val_loss: 0.0891\n",
            "Epoch 90/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0189 - val_accuracy: 0.9747 - val_loss: 0.0905\n",
            "Epoch 91/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0186 - val_accuracy: 0.9753 - val_loss: 0.0894\n",
            "Epoch 92/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0183 - val_accuracy: 0.9751 - val_loss: 0.0905\n",
            "Epoch 93/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0192 - val_accuracy: 0.9753 - val_loss: 0.0911\n",
            "Epoch 94/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0171 - val_accuracy: 0.9746 - val_loss: 0.0898\n",
            "Epoch 95/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0179 - val_accuracy: 0.9742 - val_loss: 0.0904\n",
            "Epoch 96/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0174 - val_accuracy: 0.9749 - val_loss: 0.0896\n",
            "Epoch 97/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0164 - val_accuracy: 0.9746 - val_loss: 0.0910\n",
            "Epoch 98/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0158 - val_accuracy: 0.9751 - val_loss: 0.0898\n",
            "Epoch 99/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0158 - val_accuracy: 0.9749 - val_loss: 0.0904\n",
            "Epoch 100/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0157 - val_accuracy: 0.9751 - val_loss: 0.0899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.0899\n",
            "Test accuracy: 0.9772999882698059\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "EPOCHS = 100   \t \t\t\t######  epochs에 따른 비교실험 진행 시 변경 (default: 100)\n",
        "BATCH_SIZE = 128      # 한 번에 모델이 학습하는 데이터 샘플의 개수\n",
        "NB_CLASSES = 10 \t\t\t# 분류해야할 클래스의 수\n",
        "N_HIDDEN = 256  \t  \t###### hidden neuron 수에 따른 비교실험 진행 시 변경 (default: 128)\n",
        "L_HIDDEN = 3  \t\t\t\t###### hidden layer 수에 따른 비교실험 진행 시 변경 (default: 2)\n",
        "VALIDATION_SPLIT=0.2\n",
        "\n",
        "# 데이터집합 다운로드 (train #: 60000, test #: 10000)\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "RESHAPED = 784\n",
        "## fully-connected layer의 입력으로 들어갈 수 있게 입력 영상을 일렬로 변경 (28 X 28 -> 784)\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "\n",
        "# 모델 빌드\n",
        "# 하나의 fully-connected layer만으로 구성 (변경 금지)\n",
        "model = tf.keras.models.Sequential()\n",
        "# Input layer 추가\n",
        "model.add(keras.layers.InputLayer(input_shape=(RESHAPED,)))\n",
        "# Hidden layers 추가\n",
        "for i in range(L_HIDDEN):\n",
        "\tmodel.add(keras.layers.Dense(N_HIDDEN\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t, name='dense_layer_{}'.format(i+1)\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t, activation='relu'))\n",
        "# Output layer 추가\n",
        "model.add(keras.layers.Dense(NB_CLASSES\n",
        "                             , name='output_layer'\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t , activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# optimizer, loss함수, 평가지표 설정 (변경 금지)\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습 시작\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "# 모델 저장\n",
        "model.save(\"/content/Mydrive/MyDrive/model/train_three_layer_Nhidden256.h5\")\n",
        "\n",
        "# 학습된 모델 평가\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3CXGPIiSV29",
        "outputId": "e2999d41-4562-4f0a-9ad4-9736ce863874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIDUjIZcVEUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}